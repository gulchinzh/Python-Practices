{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcbcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.select_dtypes('object').columns:\n",
    "    #if len(df[i].unique())<100:\n",
    "        print(i , \"\\n\"\"\\n\", df[i].value_counts(),\"\\n\",\"\\n\",\"**********************************\"\"\\n\\n\")\n",
    "    #else :\n",
    "        #print(\"\\n\",\"***\",i,\"***\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbce7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.select_dtypes(['int64','float64']).columns:\n",
    "    if len(df[i].unique())<100:\n",
    "        print(i , \"\\n\"\"\\n\", df[i].value_counts(dropna = False),\"\\n\",\"\\n\",\"**********************************\"\"\\n\\n\")\n",
    "    else :\n",
    "        print(\"\\n\",\"***\",i,\"***\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df[\"gender\"] == \"Other\")].index, axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.features import RadViz\n",
    "plt.rcParams[\"figure.figsize\"] = (9,5)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45764135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(),annot = True)\n",
    "#Ã§ok yÃ¼ksek correlasyon var demek o feature Ä±n Ã¶nemli olduÄŸu anlamÄ±na gelmiyor. feature'larÄ± le corr.lar ile Ã§arparak (ve intercept ekleyerek) karar verebiliriz.\n",
    "\n",
    "df_numeric.corr()[(df_numeric.corr()>= 0.9) & (df_numeric.corr() < 1)].any().any() \n",
    "\n",
    "# ilk any nÃ¼merik columlarÄ±n corr larÄ±nda 0.9 - 1 arasÄ±nda olanlarÄ±nÄ± True dÃ¶ndÃ¼rÃ¼r. diÄŸerlerini False dÃ¶ndÃ¼rÃ¼r\n",
    "# ikinci any ile ilk any'nin result'Ä± Ã¼zerinde True kontrolÃ¼ yapmÄ±ÅŸ oluyoruz. yani ikinci any ile kullandÄ±ÄŸÄ±mÄ±zda True varsa\n",
    "# tek any'li haline bakÄ±p hangileri True ona bakabiliriz. iki any'li halinde True yoksa demek ki hiÃ§ true yoktur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='bmi', y='age', data=df)\n",
    "sns.histplot(df['price'], bins = 50, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a33650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.price)\n",
    "---------------------------------------------------------\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(x=\"make_model\", y=\"price\", data=df, whis=3)\n",
    "plt.show()\n",
    "#outlierlara baxmaq ucun kodlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f560a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bmi.fillna(df['bmi'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('stroke', axis =1) # datasetimizden 'stroke' target imizi atiriq, featurlerimiz qalir onu da X a beraber edirik\n",
    "y = df['stroke'] # 'stroke' targetimizi y beraber edirik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(include =['object'])  # yada (include =['int64'])\n",
    "# data type lari object -- categorical olan feauterleri getir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isna().any()].tolist() # icinde NaN value lari olan featurelerin adlarini getirir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select_dtypes(include =\"object\").head()\n",
    "\n",
    "# datasetimdeki object feature larÄ± getirmesi iÃ§in ,dataframe formasinda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('object').columns #sadece featurelarin adlarini verir\n",
    "df_numeric = df.select_dtypes(include =\"number\") # yalniz numeric featurelari verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('object').columns:\n",
    "    print(f\"{col:<20}:\", df[col].nunique())  # col:<20 aÅŸaÄŸÄ±da print result'Ä± olarak sÃ¼tun gerniÅŸliÄŸini ayarlÄ±yor\n",
    "    \n",
    "# aÅŸaÄŸÄ±daki unique deÄŸer sayÄ±sÄ± yÃ¼ksek olan 4 column ile missing value lar ile mÃ¼cadele kapsamÄ±nda ciddi anlamda mÃ¼cadele etmek gerekiyor ama bu dersin konusu bu deÄŸil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.make_model==\"Audi A2\"]\n",
    "\n",
    "# drop edeceÄŸim Audi A2'nin satÄ±r numarasÄ±nÄ± Ã¶ÄŸrendim\n",
    "df.drop(index = [2614], inplace = True)\n",
    "\n",
    "# Audi A2'yi drop ettim\n",
    "\n",
    "# ya da\n",
    "df = df[df.gender != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19605501",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.make_model.unique():\n",
    "    print(i, \"\\t:\", skew(df[df[\"make_model\"] ==i][\"price\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri.dropna(subset = [\"driver_gender\"], inplace = True)\n",
    "# subset kullanmadan dropna yaptÄ±ÄŸÄ±mda NaN olan deÄŸerleri dÃ¼ÅŸÃ¼rÃ¼nce iÃ§inde NaN deÄŸer olan tÃ¼m sÃ¼tunlarÄ±n satÄ±rlarÄ± \n",
    "#gitmiÅŸ olacak. ama o satÄ±rda iÃ§inde deÄŸerli veri olan sÃ¼tunlar da olabilir. Bunu subset ile yapacaÄŸÄ±z ve sadece\n",
    "#belirttiÄŸimiz sÃ¼tundaki NaN olan deÄŸerlerin satÄ±rlarÄ±nÄ± silecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d142a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri[\"is_arrested\"] = ri.is_arrested.astype(\"bool\")\n",
    "\n",
    "# ri[\"is_arrested\"] serie sini iÃ§eriÄŸini bool yapÄ±p kendisine eÅŸitliyorum. yani bool'a deÄŸiÅŸtirmiÅŸ oluyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b747b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ä°ki pandas serisini str.cat() fonksiyonunu kullanarak birleÅŸtireceÄŸim.\n",
    "#stop_date'i .str.cat()' in iÃ§ine pas edeceÄŸim ri.stop_time ile birleÅŸtireceÄŸim.\n",
    "#ve bunu combined adlÄ± deÄŸiÅŸkene atayacaÄŸÄ±m.\n",
    "\n",
    "combined = ri.stop_date.str.cat(ri.stop_time, sep = \" \")\n",
    "ri[\"stop_datetime\"] = pd.to_datetime(combined)\n",
    "\n",
    "# ÅŸimdi eski iki sÃ¼tunu drop edelim.\n",
    "\n",
    "ri.drop([\"stop_date\", \"stop_time\"], axis = \"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri.set_index(\"stop_datetime\", inplace = True)\n",
    "\n",
    "# stop_datetime sÃ¼tunumu index yaptÄ±m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_and_speeding = ri[(ri.driver_gender == \"F\") & (ri.violation == \"Speeding\")]\n",
    "\n",
    "# hem female olanlarÄ± hem de violationÄ± sadece speeding olanlarÄ± getir.\n",
    "# artÄ±k female_and_speeding bu bilgilerden oluÅŸan satÄ±rlarÄ± getirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! normalize mantÄ±ÄŸÄ± ÅŸunla aynÄ±dÄ±r:\n",
    "\n",
    "# male.violation.value_counts(normalize = True)\n",
    "# male.violation.value_counts() / male.violation.value_counts().sum()\n",
    "\n",
    "#ya da :\n",
    "\n",
    "#for i in unique_vol:\n",
    "    print(i / unique_amount * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)  \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    R2_score = r2_score(actual, pred)\n",
    "    print(\"Model testing performance:\")\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"R2_score \\t: {R2_score}\")\n",
    "    print(f\"MAE \\t\\t: {mae}\")\n",
    "    print(f\"MSE \\t\\t: {mse}\")\n",
    "    print(f\"RMSE \\t\\t: {rmse}\")\n",
    "y_train_pred = lm.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred)\n",
    "y_pred = lm.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge(alpha=1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alpha_space = np.linspace(0.01, 1, 100)\n",
    "ridge_cv_model = RidgeCV(alphas = alpha_space, cv = 10, scoring = \"neg_root_mean_squared_error\")\n",
    "ridge_cv_model.fit(X_train, y_train)\n",
    "y_pred = ridge_cv_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "y_train_pred = ridge_cv_model.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred) \n",
    "\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "lasso_model = Lasso(alpha = 1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_train_pred = lasso_model.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred)\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "\n",
    "lasso_cv_model = LassoCV(alphas = alpha_space, cv = 10, max_iter = 100000) \n",
    "lasso_cv_model.fit(X_train, y_train)\n",
    "y_train_pred = lasso_cv_model.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred)\n",
    "y_pred = lasso_cv_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "lasso_cv_model.coef_\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "elastic_cv_model = ElasticNetCV(alphas = alpha_space, cv = 10, max_iter = 100000)\n",
    "elastic_cv_model.fit(X_train, y_train)\n",
    "y_train_pred = elastic_cv_model.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred)\n",
    "y_pred = elastic_cv_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486869e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train) \n",
    "x_test = scaler.transform(x_test)\n",
    "# burada x_traine fit_transform, x_teste transform edirik ki data leak ici engellemek ucun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean().iplot(kinde ='bar', subplots =True) # Null value larin mean ini bar plot seklinde visual gosterir, \n",
    "                                                       # cok ise yaraya bilir\n",
    "msno.bar(df); # bu kodlari yuxaridakinin altindan da yaza bilerik istersek, nerelerde variable llarin kayip oldugunu ya da olmadigini gormus oluruq\n",
    "msno.matrix(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean()) # nall valuelari mean le doldurmaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eger data mizda skew ness varsa her zaman safe side da qalamq icin <median> ni kullanmak lazim, null velu lari doldurmaq ucun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'].value_counts(normalize = True) # normalize true yuzdesine baxir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ama evvel iplot un librarisini import etmek lazim\n",
    "\n",
    "1-- df['col'].iplot(kind = 'hist') # rahat sunum yapa bilmemiz icin gorsel\n",
    "\n",
    "\n",
    "2-- df['col'].iplot(kind = 'histogram', subplots = True, bins =50) # rahat sunum yapa bilmemiz icin gorsel\n",
    "\n",
    "3-- df.iplot(subplots =True, subplots_titles =True,legend =False, shape(2,5) ,kind ='histogram')  # rahat sunum yapa bilmemiz icin gorsel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missin value larla ilgili kodeðŸŽˆ cok ise yararli, cedvel seklinde hem yuzdesini, hem de numberini gosterir\n",
    "def missing (df):\n",
    "    missing_number = df.isnull().sum().sort_values(ascending =False)\n",
    "    missing_percent = df.isnull().sum() / df.isnull().count().sort_values(ascending = False)\n",
    "    missing_values = pd.concat([missing_number,missing_percent], axis =1 , keys = ['Missing_Number' , 'Missing_Percent'])\n",
    "    return missing_values\n",
    "missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topla_10 (x):\n",
    "    return x + 10\n",
    "\n",
    "df.apply(topla_10) # yazdiqda her columndaki deyerlerin uzerine 10 elave edir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c860ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cixma (x):\n",
    "    return x['A_col'] - x['B_col']\n",
    "\n",
    "df.apply(cixma, axis =1) # A_col dan B_col u cixir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# how many total missing values do we have?\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "percent_missing = (total_missing/total_cells) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e8056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df.loc[:, 'Street Number Suffix':'Zipcode'].head() # icinde missing valuelari olan columnlara baxmaq ucun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410febc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na_imputed = df.fillna(method='bfill', axis=0).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['date'].head()) #column un headine de baxa bilirik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but the most common are %d for day, %m for month, %y for a two-digit year and %Y for a four digit year.\n",
    "\n",
    "# Some examples:\n",
    "\n",
    "# 1/17/07 has the format \"%m/%d/%y\"\n",
    "# 17-1-2007 has the format \"%d-%m-%Y\"\n",
    "\n",
    "df['date_parsed'] = pd.to_datetime(df['date'], format=\"%m/%d/%y\") \n",
    "# date column unun dtype i 'Object' idi, ama icindeki deyerler tarix formasinda yazilmisdi,\n",
    "# 'Object' dtype i datetime dtype a convert etdik, column un adini date_parsed yazdiq\n",
    " \n",
    "# sometimes you'll run into an error when there are multiple date formats in a single column.\n",
    "df['date_parsed'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
    "# infer_datetime_format = True ---> bir column da multiple date formatlar var ise error olmasinin qarsisini alir\n",
    "\n",
    "df = df['date_parsed'].dt.day\n",
    "# kalendardan yalniz aylari getirir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() # ne kadar duplicat deyer var\n",
    "df[df.duplicated()] # duplicat deyerleri dataframe kimi gosterir\n",
    "df.drop_duplicates(inplace=True) # duplicat leri silmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame i biz list , dictionary , nympy arrayle olustura bilerik\n",
    "df.head() # ilk 5 row u getirir default u 5 dir\n",
    "df.tail()# son 5 row u getiri\n",
    "df.sample() # datamizin icinden herhansi bir row u getirir, icine ne reqemi yazarsaq o qeder row getirir\n",
    "df.columns # datamizin icindeki column adlarini getirir\n",
    "df.shape() # datamizin nece row ve columndan olustugunu getirir\n",
    "df['col_name'].values() # columnun icindeki deyerleri getirir\n",
    "df['new_col'] = df['a_col'] + df['b_col'] # yeni column duzeltdikde iki col u toplaya cixa vura bole bilerik\n",
    "# fazlalik yapmamasi icin df['a'] ve df['b']  df.drop('col_name', axis =1)\n",
    "df.drop('col_name', axis =1) # col u silmek ucun\n",
    "df.drop(sira_nomresi , axis =0) # kalici olmasini isteyirikse inplace = True\n",
    "# indexle bagli drop etdikden sonra reset_index etmek lazimdir\n",
    "df.reset_index(drop = True) # qalici olmasi ucun de drop = True yaziriq\n",
    "df.loc[2] # sira nomresi 2 olan row u getir\n",
    "df.loc[2:5] # sira nomresi 2 ve 5 olan(5 daxildir) rowlari getir\n",
    "df.iloc[2:5] # sira nomresi 2 ve 5 olan(5 deyil) rowlari getir\n",
    "df.iloc[2:5, 3:5] # 2:5 1ci rowlari secirik, 2ci 3:5 columnlari\n",
    "df.loc[2:5]['a_col'] # ['a_col'] columundaki sira nomresi 2 ve 5 (daxildir) arasinda olan deyerleri getir . Serie formasinda\n",
    "df.loc[2:5][['a_col']] # kvadrat motereze iki qat olanda DFrame olur\n",
    "df.loc[index num][['col_name']] ðŸ˜‰\n",
    "df.loc[: ,[['a_col']]] # a_col un row larinin hamisini al\n",
    "df.['a_col'] # buda columun butun row larini getirir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab946978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteringi & | !=  == > < edirik\n",
    "\n",
    "df[(df['a_col'] > 0) & (df['b_col'] > 2)] # a_col da 0 dan boyuk, b_col da 2 den boyuk olan deyerleri getirir\n",
    "df[(df['a_col'] > 0) & (df['b_col'] > 2)].shape\n",
    "df[(df[col1]>2) & (df[col2]==222)]\n",
    "df[df['price'] > 300 ] # 'price' i 300 den yuxari olanlari getir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cffa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'].min() # col un icindeki min deyeri verir (max,std,mean,max,mode,median da qoya bilerik)\n",
    "df['col'].idxmin() # col un minimum deyerinin index numberini verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddcb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('col_1')['col2'].mean() # col1 i col2 ye gore groupla ve onlarin mean(max,std,mean,max,mode,median da qoya biler)\n",
    "df.groupby('col_1')['col2'].describe().T['Value'] # 'col_1 in icindeki her hansi bir Value ya baxa bilerik'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c571eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.col.unique() # sutunun icinde nece eded benzersiz(unikal) deyer\n",
    "df.col.nunique() # unikal deyerlerin sayini verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = 'col_1', asending = False) # col_1 in value larini siralayir , False oldugu ucun coxdan aza, True olsaydi azdan coxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e563b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eger dataset de NaN value lar varsa butun NaN lari hello ile doldurur\n",
    "df.fillna('hello')\n",
    "\n",
    "# column un NaN valuelarini mean, median, mode la doldura bilirik\n",
    "df['col2'].fillna(df.col2.mean())\n",
    "df['col'].fillna('bfill') # backfill ozunden sonrakiyla doldurur\n",
    "df['col'].fillna('ffill') # frontfill ozunden sonrasiyla doldurur\n",
    "df['colf'].fillna(method='ffill', limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb777758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lamda x: x.fillna(x.mean()), axis =0) # setir boyunca missing valu lari mean le doldurur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'] = df['col'].map(lambda x: x*10) # 'col' un icindeki deyerleri lambda ile 10 a vurub, map ile 'col'un icine qoyuruq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c145590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company'] = df['company'].replace('Goo','Google') # 'company' columnun icinde harada Goo gorse Google la evezle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b717c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company'] = df['company'].astype(str) # column un typeni str ya deyisdik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function\n",
    "\n",
    "def multiply (x):\n",
    "    return x * 10\n",
    "\n",
    "df['col'] = df['col'].apply(multiply)\n",
    "\n",
    "# yuxarida yaratdigimiz multiply functionunu asagida apply la 'col' un value larina tetbiq etdik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3a9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('col1')['col2'].mean()  # 'col1' i 'col2' nin ortalamasina gore qrupla\n",
    "\n",
    "df.groupby(['col1','col2'])['col3'].mean() # 'col1' ve 'col2' ni 'col3' un ortalamsina gore qruplandir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_name'].value_counts() # icinde hansi deyerden nece eded oldugunu gosterir\n",
    "sns.countplot(df['col_name']) # value_counts() kimidir visual olaraq gosterir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743257a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull.sum()  # datamizdaki her columnun ayri-ayri resultini verir\n",
    "df.isnull().any()  # datamizdaki deyerlerin NaN oldugunu boolin olaraq True yada False getirir\n",
    "df.isnull().sum().sum()  # datamizdaki NaN value lar hansi columnlardadirsa onlarin umumi cemini getirir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0utlier\n",
    "sns.boxplot(x = np.log(df['col_name'])) # bu kod saga skew olan datalarcun istifade olunur,\n",
    "                                        # sagdaki outlayerleri temizleyende log funtion dan ist olun\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a6ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
