{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcbcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.select_dtypes('object').columns:\n",
    "    #if len(df[i].unique())<100:\n",
    "        print(i , \"\\n\"\"\\n\", df[i].value_counts(),\"\\n\",\"\\n\",\"**********************************\"\"\\n\\n\")\n",
    "    #else :\n",
    "        #print(\"\\n\",\"***\",i,\"***\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbce7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.select_dtypes(['int64','float64']).columns:\n",
    "    if len(df[i].unique())<100:\n",
    "        print(i , \"\\n\"\"\\n\", df[i].value_counts(dropna = False),\"\\n\",\"\\n\",\"**********************************\"\"\\n\\n\")\n",
    "    else :\n",
    "        print(\"\\n\",\"***\",i,\"***\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df[\"gender\"] == \"Other\")].index, axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.features import RadViz\n",
    "plt.rcParams[\"figure.figsize\"] = (9,5)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45764135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(),annot = True)\n",
    "#Ã§ok yÃ¼ksek correlasyon var demek o feature Ä±n Ã¶nemli olduÄŸu anlamÄ±na gelmiyor. feature'larÄ± le corr.lar ile Ã§arparak (ve intercept ekleyerek) karar verebiliriz.\n",
    "\n",
    "df_numeric.corr()[(df_numeric.corr()>= 0.9) & (df_numeric.corr() < 1)].any().any() \n",
    "\n",
    "# ilk any nÃ¼merik columlarÄ±n corr larÄ±nda 0.9 - 1 arasÄ±nda olanlarÄ±nÄ± True dÃ¶ndÃ¼rÃ¼r. diÄŸerlerini False dÃ¶ndÃ¼rÃ¼r\n",
    "# ikinci any ile ilk any'nin result'Ä± Ã¼zerinde True kontrolÃ¼ yapmÄ±ÅŸ oluyoruz. yani ikinci any ile kullandÄ±ÄŸÄ±mÄ±zda True varsa\n",
    "# tek any'li haline bakÄ±p hangileri True ona bakabiliriz. iki any'li halinde True yoksa demek ki hiÃ§ true yoktur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='bmi', y='age', data=df)\n",
    "sns.histplot(df['price'], bins = 50, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a33650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.price)\n",
    "---------------------------------------------------------\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(x=\"make_model\", y=\"price\", data=df, whis=3)\n",
    "plt.show()\n",
    "#outlierlara baxmaq ucun kodlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f560a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bmi.fillna(df['bmi'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('stroke', axis =1) # datasetimizden 'stroke' target imizi atiriq, featurlerimiz qalir onu da X a beraber edirik\n",
    "y = df['stroke'] # 'stroke' targetimizi y beraber edirik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(include =['object'])  # yada (include =['int64'])\n",
    "# data type lari object -- categorical olan feauterleri getir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isna().any()].tolist() # icinde NaN value lari olan featurelerin adlarini getirir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select_dtypes(include =\"object\").head()\n",
    "\n",
    "# datasetimdeki object feature larÄ± getirmesi iÃ§in ,dataframe formasinda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('object').columns #sadece featurelarin adlarini verir\n",
    "df_numeric = df.select_dtypes(include =\"number\") # yalniz numeric featurelari verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes('object').columns:\n",
    "    print(f\"{col:<20}:\", df[col].nunique())  # col:<20 aÅŸaÄŸÄ±da print result'Ä± olarak sÃ¼tun gerniÅŸliÄŸini ayarlÄ±yor\n",
    "    \n",
    "# aÅŸaÄŸÄ±daki unique deÄŸer sayÄ±sÄ± yÃ¼ksek olan 4 column ile missing value lar ile mÃ¼cadele kapsamÄ±nda ciddi anlamda mÃ¼cadele etmek gerekiyor ama bu dersin konusu bu deÄŸil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.make_model==\"Audi A2\"]\n",
    "\n",
    "# drop edeceÄŸim Audi A2'nin satÄ±r numarasÄ±nÄ± Ã¶ÄŸrendim\n",
    "df.drop(index = [2614], inplace = True)\n",
    "\n",
    "# Audi A2'yi drop ettim\n",
    "\n",
    "# ya da\n",
    "df = df[df.gender != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19605501",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.make_model.unique():\n",
    "    print(i, \"\\t:\", skew(df[df[\"make_model\"] ==i][\"price\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri.dropna(subset = [\"driver_gender\"], inplace = True)\n",
    "# subset kullanmadan dropna yaptÄ±ÄŸÄ±mda NaN olan deÄŸerleri dÃ¼ÅŸÃ¼rÃ¼nce iÃ§inde NaN deÄŸer olan tÃ¼m sÃ¼tunlarÄ±n satÄ±rlarÄ± \n",
    "#gitmiÅŸ olacak. ama o satÄ±rda iÃ§inde deÄŸerli veri olan sÃ¼tunlar da olabilir. Bunu subset ile yapacaÄŸÄ±z ve sadece\n",
    "#belirttiÄŸimiz sÃ¼tundaki NaN olan deÄŸerlerin satÄ±rlarÄ±nÄ± silecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d142a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri[\"is_arrested\"] = ri.is_arrested.astype(\"bool\")\n",
    "\n",
    "# ri[\"is_arrested\"] serie sini iÃ§eriÄŸini bool yapÄ±p kendisine eÅŸitliyorum. yani bool'a deÄŸiÅŸtirmiÅŸ oluyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b747b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ä°ki pandas serisini str.cat() fonksiyonunu kullanarak birleÅŸtireceÄŸim.\n",
    "#stop_date'i .str.cat()' in iÃ§ine pas edeceÄŸim ri.stop_time ile birleÅŸtireceÄŸim.\n",
    "#ve bunu combined adlÄ± deÄŸiÅŸkene atayacaÄŸÄ±m.\n",
    "\n",
    "combined = ri.stop_date.str.cat(ri.stop_time, sep = \" \")\n",
    "ri[\"stop_datetime\"] = pd.to_datetime(combined)\n",
    "\n",
    "# ÅŸimdi eski iki sÃ¼tunu drop edelim.\n",
    "\n",
    "ri.drop([\"stop_date\", \"stop_time\"], axis = \"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ri.set_index(\"stop_datetime\", inplace = True)\n",
    "\n",
    "# stop_datetime sÃ¼tunumu index yaptÄ±m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_and_speeding = ri[(ri.driver_gender == \"F\") & (ri.violation == \"Speeding\")]\n",
    "\n",
    "# hem female olanlarÄ± hem de violationÄ± sadece speeding olanlarÄ± getir.\n",
    "# artÄ±k female_and_speeding bu bilgilerden oluÅŸan satÄ±rlarÄ± getirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! normalize mantÄ±ÄŸÄ± ÅŸunla aynÄ±dÄ±r:\n",
    "\n",
    "#male.violation.value_counts(normalize = True)\n",
    "#male.violation.value_counts() / male.violation.value_counts().sum()\n",
    "\n",
    "#ya da :\n",
    "\n",
    "#for i in unique_vol:\n",
    "    print(i / unique_amount * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)  \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    R2_score = r2_score(actual, pred)\n",
    "    print(\"Model testing performance:\")\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"R2_score \\t: {R2_score}\")\n",
    "    print(f\"MAE \\t\\t: {mae}\")\n",
    "    print(f\"MSE \\t\\t: {mse}\")\n",
    "    print(f\"RMSE \\t\\t: {rmse}\")\n",
    "y_train_pred = lm.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred)\n",
    "y_pred = lm.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge(alpha=1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alpha_space = np.linspace(0.01, 1, 100)\n",
    "ridge_cv_model = RidgeCV(alphas = alpha_space, cv = 10, scoring = \"neg_root_mean_squared_error\")\n",
    "ridge_cv_model.fit(X_train, y_train)\n",
    "y_pred = ridge_cv_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "y_train_pred = ridge_cv_model.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred) \n",
    "\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "lasso_model = Lasso(alpha = 1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_train_pred = lasso_model.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred)\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "\n",
    "lasso_cv_model = LassoCV(alphas = alpha_space, cv = 10, max_iter = 100000) \n",
    "lasso_cv_model.fit(X_train, y_train)\n",
    "y_train_pred = lasso_cv_model.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred)\n",
    "y_pred = lasso_cv_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)\n",
    "lasso_cv_model.coef_\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "elastic_cv_model = ElasticNetCV(alphas = alpha_space, cv = 10, max_iter = 100000)\n",
    "elastic_cv_model.fit(X_train, y_train)\n",
    "y_train_pred = elastic_cv_model.predict(X_train)\n",
    "eval_metrics(y_train, y_train_pred)\n",
    "y_pred = elastic_cv_model.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean().iplot(kinde ='bar', subplots =True) # Null value larin mean ini bar plot seklinde visual gosterir, \n",
    "                                                       # cok ise yaraya bilir\n",
    "msno.bar(df); # bu kodlari yuxaridakinin altindan da yaza bilerik istersek, nerelerde variable llarin kayip oldugunu ya da olmadigini gormus oluruq\n",
    "msno.matrix(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean()) # nall valuelari mean le doldurmaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe9747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eger data mizda skew ness varsa her zaman safe side da qalamq icin <median> ni kullanmak lazim, null velu lari doldurmaq ucun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'].value_counts(normalize = True) # normalize true yuzdesine baxir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ama evvel iplot un librarisini import etmek lazim\n",
    "\n",
    "1-- df['col'].iplot(kind = 'hist') # rahat sunum yapa bilmemiz icin gorsel\n",
    "\n",
    "\n",
    "2-- df['col'].iplot(kind = 'histogram', subplots = True, bins =50) # rahat sunum yapa bilmemiz icin gorsel\n",
    "\n",
    "3-- df.iplot(subplots =True, subplots_titles =True,legend =False, shape(2,5) ,kind ='histogram')  # rahat sunum yapa bilmemiz icin gorsel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missin value larla ilgili kodeðŸŽˆ cok ise yararli, cedvel seklinde hem yuzdesini, hem de numberini gosterir\n",
    "def missing (df):\n",
    "    missing_number = df.isnull().sum().sort_values(ascending =False)\n",
    "    missing_percent = df.isnull().sum() / df.isnull().count().sort_values(ascending = False)\n",
    "    missing_values = pd.concat([missing_number,missing_percent], axis =1 , keys = ['Missing_Number' , 'Missing_Percent'])\n",
    "    return missing_values\n",
    "missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of missing data points per column\n",
    "missing_values_count = df.isnull().sum()\n",
    "\n",
    "# how many total missing values do we have?\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "percent_missing = (total_missing/total_cells) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e8056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df.loc[:, 'Street Number Suffix':'Zipcode'].head() # icinde missing valuelari olan columnlara baxmaq ucun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410febc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na_imputed = df.fillna(method='bfill', axis=0).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['date'].head()) #column un headine de baxa bilirik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but the most common are %d for day, %m for month, %y for a two-digit year and %Y for a four digit year.\n",
    "\n",
    "# Some examples:\n",
    "\n",
    "# 1/17/07 has the format \"%m/%d/%y\"\n",
    "# 17-1-2007 has the format \"%d-%m-%Y\"\n",
    "\n",
    "df['date_parsed'] = pd.to_datetime(df['date'], format=\"%m/%d/%y\") \n",
    "# date column unun dtype i 'Object' idi, ama icindeki deyerler tarix formasinda yazilmisdi,\n",
    "# 'Object' dtype i datetime dtype a convert etdik, column un adini date_parsed yazdiq\n",
    " \n",
    "# sometimes you'll run into an error when there are multiple date formats in a single column.\n",
    "df['date_parsed'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
    "# infer_datetime_format = True ---> bir column da multiple date formatlar var ise error olmasinin qarsisini alir\n",
    "\n",
    "df = df['date_parsed'].dt.day\n",
    "# kalendardan yalniz aylari getirir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d4897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
